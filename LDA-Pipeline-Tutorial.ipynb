{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Dirichlet Allocation (LDA) Pipeline Example in Python\n",
    "\n",
    "Below is a tutorial on how to process data and to train an LDA on it. \n",
    "\n",
    "Knowing that the LDA perform better with stop words removal and with lemmatized words, it's results are often ugly on the lemmatized words. To fix that, it's a good thing to be able to do an inverse-lemmatization on the topic words (or topic n-grams) yield by the LDA once trained on the data. \n",
    "\n",
    "So here we are: let's do a pipeline that looks like that: \n",
    "\n",
    "1. Load a dataset of many comments (or documents)\n",
    "2. Transform comments to remove stop words\n",
    "3. Lemmatize the comments without stop words for a better LDA\n",
    "4. Perform LDA topic modeling\n",
    "5. Recover words from inverse (backwards) lemmatization on topic words \n",
    "6. Clean topic words are available\n",
    "\n",
    "Note: The classes imported are clean and have unit tests. Don't hesitate to dive in and to check what's under the hood!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from app.data.load_sample_data import load_sample_data\n",
    "from app.logic.stop_words_remover import StopWordsRemover\n",
    "from app.logic.stemmer import Stemmer\n",
    "from app.logic.lda import LDA\n",
    "from app.logic.count_vectorizer import CountVectorizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a dataset of many comments (or documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids, messages, comments = load_sample_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform comments to remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_en_stopwords = StopWordsRemover()\n",
    "comments_without_stopwords = fr_en_stopwords.transform(comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatize the comments without stop words for clean texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "french_stemmer = Stemmer(language='french')\n",
    "stemmed_comments = [french_stemmer.fit_transform(thread) for thread in comments_without_stopwords]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform LDA topic modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lda = LDA(n_components=2, max_iter=5, learning_method='online', learning_offset=50.)\n",
    "# lda_sklearn, feature_names = lda.fit(stemmed_comments[-4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recover words from inverse (backwards) lemmatization on topic words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some clean topic words (or expressions) are then available!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: clean below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = -2\n",
    "chosen_id = ids[i]\n",
    "chosen_message = messages[i]\n",
    "chosen_comments = comments[i]\n",
    "# chosen_id, chosen_message, chosen_comments, str(len(chosen_comments)) + \" comments.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "lda_pipeline = Pipeline([\n",
    "    ('stopwords', StopWordsRemover()),\n",
    "    ('stemmer', Stemmer()),\n",
    "    # ('letter_splitter', LetterSplitter()),\n",
    "    ('count_vect', CountVectorizer()),\n",
    "    ('lda', LDA()),\n",
    "])\n",
    "\n",
    "# Params where many options are in lists represents choice in the later grid search. \n",
    "lda_pipeline_params = {\n",
    "    'stemmer__language': ['french'],\n",
    "    'count_vect__max_df': [0.98, 0.95],\n",
    "    'count_vect__min_df': [2, 3],\n",
    "    'count_vect__max_features': [10000],\n",
    "    'count_vect__ngram_range': [(1, 1), (1, 2)],\n",
    "    'count_vect__strip_accents': ['ascii', 'unicode', None],\n",
    "    'lda__n_components': [2],\n",
    "    'lda__max_iter': [100],  # TODO: find good balance here.\n",
    "    'lda__learning_decay': [0.5, 0.7, 1.0],\n",
    "    'lda__learning_method': ['online'],\n",
    "    'lda__learning_offset': [5, 10],\n",
    "    'lda__batch_size': [1, 10, 25],\n",
    "    # 'lda__n_jobs': -1,  # Use all CPUs\n",
    "}\n",
    "# \"\"\"\n",
    "lda_pipeline_params = {\n",
    "    'stemmer__language': ['french'],\n",
    "    'count_vect__max_df': [0.98],\n",
    "    'count_vect__min_df': [2],\n",
    "    'count_vect__max_features': [10000],\n",
    "    'count_vect__ngram_range': [(1, 2)],\n",
    "    'count_vect__strip_accents': [None],\n",
    "    'lda__n_components': [2],\n",
    "    'lda__max_iter': [1000],  # TODO: find good balance here.\n",
    "    'lda__learning_decay': [0.5],\n",
    "    'lda__learning_method': ['online'],\n",
    "    'lda__learning_offset': [10],\n",
    "    'lda__batch_size': [25],\n",
    "    # 'lda__n_jobs': -1,  # Use all CPUs\n",
    "}\n",
    "# \"\"\"\n",
    "\n",
    "\n",
    "# TODO: Might need to code a custom parameter search\n",
    "gs = GridSearchCV(lda_pipeline, lda_pipeline_params, n_jobs=-1, verbose=1, cv=2)\n",
    "gs.fit(chosen_comments)\n",
    "print(\"Best score: {}\".format(gs.best_score_))\n",
    "\n",
    "\n",
    "\n",
    "best_params = gs.best_estimator_.get_params()\n",
    "# import pprint\n",
    "# pp = pprint.PrettyPrinter(indent=4)\n",
    "# print(type(best_params))\n",
    "# pp.pprint(best_params)\n",
    "\n",
    "best_pipeline = Pipeline(best_params['steps'])\n",
    "transformed_comments = best_pipeline.fit_transform(chosen_comments)\n",
    "print(\"score:\", best_pipeline.score(chosen_comments))\n",
    "\n",
    "features = best_pipeline.named_steps['count_vect'].get_feature_names()\n",
    "lda = best_pipeline.named_steps['lda']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lda = best_pipeline.named_steps['lda']\n",
    "topics = lda.components_\n",
    "# print(topics)\n",
    "print(\"\")\n",
    "topic_words = best_pipeline.inverse_transform(X=None)\n",
    "print(\"\")\n",
    "print(topic_words[0])\n",
    "print(topic_words[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Some print-info to clean later on\n",
    "\n",
    "from app.application.data_utils import link_topics_and_weightings\n",
    "\n",
    "print(\"# Unique ID:\")\n",
    "print(chosen_id)\n",
    "print(\"\\n# Message:\")\n",
    "print(chosen_message)\n",
    "print(\"\\n# Comments:\")\n",
    "print(chosen_comments)\n",
    "print(\"\\n# Topics' ponderation in each comment:\")\n",
    "print(transformed_comments)\n",
    "print(\"\\n# Topics' words:\")\n",
    "print(topic_words)\n",
    "print(\"\\n# Topic words' weighting:\")\n",
    "topic_words_weighting = [list(reversed(sorted(t))) for t in topics]\n",
    "print(topic_words_weighting)\n",
    "print(\"\\n# Alignment of topic words with their weightings (same as previous two arrays)\")\n",
    "print(link_topics_and_weightings(topic_words, topic_words_weighting))\n",
    "print(\"\\nNote: you should show only the first half of the topics' words or less, because the word list for topic includes EVERY word, so each topic have all the words but with different weightings. \"\n",
    "      \"Normally I'd trim that to a maximum word count or weighting threshold not to return every words.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print(np.array(chosen_comments))\n",
    "print(\"\\nSplitting on topics as if they were booleans:\")\n",
    "print(transformed_comments.argmax(1))\n",
    "\n",
    "group_1 = np.array(chosen_comments)[0==transformed_comments.argmax(1).astype(int)]\n",
    "group_2 = np.array(chosen_comments)[1==transformed_comments.argmax(1).astype(int)]\n",
    "\n",
    "print(\"\\nComments splitted:\")\n",
    "print(group_1)\n",
    "print(group_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # messages[-2], comments[-2]\n",
    "# # features = best_pipeline.named_steps['count_vect'].get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "lda = best_pipeline.named_steps['lda']\n",
    "count_vect = best_pipeline.named_steps['count_vect']\n",
    "stemmer = best_pipeline.named_steps['stemmer']\n",
    "\n",
    "lda.print_top_words(count_vect.get_feature_names())\n",
    "print(\"\")\n",
    "\n",
    "print(lda.components_)\n",
    "topics = lda.inverse_transform()\n",
    "print(topics)\n",
    "topics_words = count_vect.inverse_transform(topics)\n",
    "print(topics_words)\n",
    "final_words = stemmer.inverse_transform(topics_words)\n",
    "print(final_words[0])\n",
    "print(final_words[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# train, test = sklearn.model_selection.train_test_split(stemmed_comments[-2], test_size=0.2)\n",
    "# print(len(train), len(test))\n",
    "\n",
    "# lda_sklearn, feature_names = lda.fit(train)\n",
    "\n",
    "# print(lda.score(train), lda.perplexity(train))\n",
    "# print(lda.score(test), lda.perplexity(test))\n",
    "# -182.51029019702543   27.615270885701467\n",
    "# -52.05494670051718    41.19061662552155   \n",
    "# -41.973876576664225  189.9450029464927    \n",
    "# -32.432059761463556 3320.9791408284505    \n",
    "# perplexity should go down and score should go down too (more negative). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(stemmed_comments[-2]), len(stemmed_comments[-3]), len(stemmed_comments[-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ([(len(i), a) for a, i in enumerate(stemmed_comments)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fr_en_stopwords = StopWordsRemover()\n",
    "# fr_en_stopwords.remove_from_string(\"Le chat s'est assis sur le tapis aujour'hui!!! il est très comfortable et n'est pas déçu, tout ronron!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
